apiVersion: policy.open-cluster-management.io/v1
kind: PolicyGenerator
metadata:
  name: group-du-standard-latest
placementBindingDefaults:
  name: group-du-standard-placement-binding
policyDefaults:
  # categories: []
  #controls:
  #  - PR.DS-1 Data-at-rest
  namespace: ztp-group
  # Use an existing placement rule so that placement bindings can be consolidated
  placement:
    labelSelector:
      group-du-standard: ""
      du-profile: "latest"
  remediationAction: inform
  severity: low
  # standards: []
  namespaceSelector:
    exclude:
      - kube-*
    include:
      - '*'
  evaluationInterval:
    compliant: 10m
    noncompliant: 10s
policies:
- name: group-du-standard-latest-config-policy
  policyAnnotations:
    ran.openshift.io/ztp-deploy-wave: "10"
  manifests:
    - path: source-crs/PtpOperatorConfig-SetSelector.yaml
      patches:
      - spec:
          daemonNodeSelector:
            node-role.kubernetes.io/worker: ""
    - path: source-crs/PtpConfigSlave.yaml   # Change to PtpConfigSlaveCvl.yaml for ColumbiaVille NIC
      patches:
        - metadata:
            name: du-ptp-slave
          spec:
            profile:
                - interface: ens6f0
                  name: slave
                  phc2sysOpts: -a -r -n 25
                  ptp4lOpts: -2 -s --summary_interval -4
      openapi:
        path: schema.openapi
    - path: source-crs/SriovOperatorConfig-SetSelector.yaml
      # For existing clusters with node selector set as "master", 
      # change the complianceType to "mustonlyhave".
      # After complying with the policy, the complianceType can 
      # be reverted to "musthave"
      complianceType: musthave
      patches:
      - spec:
          configDaemonNodeSelector:
            node-role.kubernetes.io/worker: ""
    - path: source-crs/PerformanceProfile-SetSelector.yaml
      patches:
      - spec:
          cpu:
            # These must be tailored for the specific hardware platform
            isolated: "2-19,22-39"
            reserved: "0-1,20-21"
          hugepages:
            defaultHugepagesSize: 1G
            pages:
            - size: 1G
              count: 32
          machineConfigPoolSelector:
            pools.operator.machineconfiguration.openshift.io/worker: ""
          nodeSelector:
            node-role.kubernetes.io/worker: ''
    - path: source-crs/TunedPerformancePatch.yaml
      patches:
      - spec:
          recommend:
          - machineConfigLabels:
              machineconfiguration.openshift.io/role: "worker"
            priority: 19
            profile: performance-patch
    - path: source-crs/optional-extra-manifest/enable-crun-master.yaml
    - path: source-crs/optional-extra-manifest/enable-crun-worker.yaml
