apiVersion: policy.open-cluster-management.io/v1
kind: PolicyGenerator
metadata:
  name: example-sno-latest
placementBindingDefaults:
  name: example-sno-placement-binding
policyDefaults:
  # categories: []
  #controls:
  #  - PR.DS-1 Data-at-rest
  namespace: ztp-site
  # Use an existing placement rule so that placement bindings can be consolidated
  placement:
    labelSelector:
      # These policies will correspond to all clusters with this label:
      site: "example-sno"
      du-profile: "latest"
  remediationAction: inform
  severity: low
  # standards: []
  namespaceSelector:
    exclude:
      - kube-*
    include:
      - '*'
  evaluationInterval:
    compliant: 10m
    noncompliant: 10s
policies:
  # Create operators policies that will be installed in all clusters
- name: example-sno-latest-config-policy
  policyAnnotations:
    ran.openshift.io/ztp-deploy-wave: "100"
  manifests:
    - path: source-crs/SriovNetwork.yaml
      patches:
      - metadata:
          name: "sriov-nw-du-fh"
        spec:
          resourceName: du_fh
          vlan: 140
    - path: source-crs/SriovNetworkNodePolicy-SetSelector.yaml
      patches:
      - metadata:
          name: "sriov-nnp-du-fh"
        spec:
          deviceType: netdevice
          isRdma: false
          nicSelector:
            pfNames: ["ens5f0"]
          nodeSelector:
            node-role.kubernetes.io/master: ""
          numVfs: 8
          priority: 10
          resourceName: du_fh
    - path: source-crs/SriovNetwork.yaml
      patches:
      - metadata:
          name: "sriov-nw-du-mh"
        spec:
          resourceName: du_mh
          vlan: 150
    - path: source-crs/SriovNetworkNodePolicy-SetSelector.yaml
      patches:
      - metadata:
          name: "sriov-nnp-du-mh"
        spec:
          deviceType: vfio-pci
          isRdma: false
          nicSelector:
            pfNames: ["ens7f0"]
          nodeSelector:
            node-role.kubernetes.io/master: ""
          numVfs: 8
          priority: 10
          resourceName: du_mh
#   --- START of source CRs needed for configuring OADP operator for SNO Image Based Upgrade ---
#   - path: source-crs/OadpSecret.yaml
#     patches:
#     - data:
#         cloud: W2RlZmF1bHRdCmF3c19hY2Nlc3Nfa2V5X2lkPVdicktaSFpFOXZGWEVFemo2RU12CmF3c19zZWNyZXRfYWNjZXNzX2tleT1RRDNmRVZMNzVsOWJpSWswYW9PdlRSc2diN01ZRUlnZmF5bzVzRnlmCg==
#   - path: source-crs/OadpDataProtectionApplication.yaml
#     patches:
#     - spec:
#         backupLocations:
#         - velero:
#             provider: aws
#             default: true
#             credential:
#               key: cloud
#               name: cloud-credentials
#             config:
#               profile: "default"
#               region: minio
#               s3Url: http://s3storage.example.com:9000
#               insecureSkipTLSVerify: "true"
#               s3ForcePathStyle: "true"
#             objectStorage:
#               bucket: ibu
#               prefix: '{{hub .ManagedClusterName hub}}'
#   # If there are more than one backupLocation defined in the OadpDataProtectionApplication CR above,
#   # then each backupLocation should have a corresponding OadpBackupStorageLocation CR added below
#   # for status tracking. Ensure that the name of each additional OadpBackupStorageLocation CR is
#   # overridden with the correct index as described in the source CR comment.
#   - path: source-crs/OadpBackupStorageLocationStatus.yaml
#   --- END of source CRs needed for configuring OADP operator for SNO Image Based Upgrade ---
